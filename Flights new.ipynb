{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, scipy \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('flights.csv', low_memory=False,error_bad_lines=False)\n",
    "#df = df[df['MONTH'] == 1]\n",
    "variables_to_remove = ['TAXI_OUT', 'TAXI_IN', 'WHEELS_ON', 'WHEELS_OFF', 'YEAR', \n",
    "                       'MONTH','DAY','DAY_OF_WEEK', 'AIR_SYSTEM_DELAY',\n",
    "                       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
    "                       'WEATHER_DELAY', 'DIVERTED', 'CANCELLED', 'CANCELLATION_REASON',\n",
    "                       'FLIGHT_NUMBER', 'TAIL_NUMBER', 'AIR_TIME','ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DISTANCE', 'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'SCHEDULED_ARRIVAL','ARRIVAL_TIME','ARRIVAL_DELAY','SCHEDULED_TIME','ELAPSED_TIME']\n",
    "df.drop(variables_to_remove, axis = 1, inplace = True)\n",
    "df.dropna(inplace = True)\n",
    "#df[0:]\n",
    "#df = df[df['MONTH'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic1=dict()\n",
    "col_names=['AIRLINE','DEPARTURE_DELAY']\n",
    "df1=pd.DataFrame(columns = col_names)\n",
    "\n",
    "dic2=dict()\n",
    "df2=pd.DataFrame(columns = col_names)\n",
    "\n",
    "dic3=dict()\n",
    "df3=pd.DataFrame(columns = col_names)\n",
    "\n",
    "dic4=dict()\n",
    "df4=pd.DataFrame(columns = col_names)\n",
    "\n",
    "dic5=dict()\n",
    "df5=pd.DataFrame(columns = col_names)\n",
    "\n",
    "dic6=dict()\n",
    "df6=pd.DataFrame(columns = col_names)\n",
    "\n",
    "dic7=dict()\n",
    "df7=pd.DataFrame(columns = col_names)\n",
    "\n",
    "dic8=dict()\n",
    "df8=pd.DataFrame(columns = col_names)\n",
    "\n",
    "dic9=dict()\n",
    "df9=pd.DataFrame(columns = col_names)\n",
    "\n",
    "dic10=dict()\n",
    "df10=pd.DataFrame(columns = col_names)\n",
    "\n",
    "dic11=dict()\n",
    "df11=pd.DataFrame(columns = col_names)\n",
    "\n",
    "dic12=dict()\n",
    "df12=pd.DataFrame(columns = col_names)\n",
    "#c=0\n",
    "for a,b in df.iterrows():\n",
    "  #c=c+1\n",
    "  if b[0]=='US':\n",
    "    dic1 = {'AIRLINE':b[0], 'DEPARTURE_DELAY':b[1]}\n",
    "    df1.loc[len(df1)] = dic1\n",
    "  if b[0]=='F9':\n",
    "    dic2 = {'AIRLINE':b[0], 'DEPARTURE_DELAY':b[1]}\n",
    "    df2.loc[len(df2)] = dic2\n",
    "  if b[0]=='B6':\n",
    "    dic3 = {'AIRLINE':b[0], 'DEPARTURE_DELAY':b[1]}\n",
    "    df3.loc[len(df3)] = dic3\n",
    "  if b[0]=='OO':\n",
    "    dic4 = {'AIRLINE':b[0], 'DEPARTURE_DELAY':b[1]}\n",
    "    df4.loc[len(df4)] = dic4\n",
    "  if b[0]=='AS':\n",
    "    dic5 = {'AIRLINE':b[0], 'DEPARTURE_DELAY':b[1]}\n",
    "    df5.loc[len(df5)] = dic5\n",
    "  if b[0]=='NK':\n",
    "    dic6 = {'AIRLINE':b[0], 'DEPARTURE_DELAY':b[1]}\n",
    "    df6.loc[len(df6)] = dic6\n",
    "  if b[0]=='WN':\n",
    "    dic7 = {'AIRLINE':b[0], 'DEPARTURE_DELAY':b[1]}\n",
    "    df7.loc[len(df7)] = dic7\n",
    "  if b[0]=='DL':\n",
    "    dic8 = {'AIRLINE':b[0], 'DEPARTURE_DELAY':b[1]}\n",
    "    df8.loc[len(df8)] = dic8\n",
    "  if b[0]=='EV':\n",
    "    dic9 = {'AIRLINE':b[0], 'DEPARTURE_DELAY':b[1]}\n",
    "    df9.loc[len(df9)] = dic9\n",
    "  if b[0]=='HA':\n",
    "    dic10 = {'AIRLINE':b[0], 'DEPARTURE_DELAY':b[1]}\n",
    "    df10.loc[len(df10)] = dic10\n",
    "  if b[0]=='MQ':\n",
    "    dic11 = {'AIRLINE':b[0], 'DEPARTURE_DELAY':b[1]}\n",
    "    df11.loc[len(df11)] = dic11\n",
    "  if b[0]=='VX':\n",
    "    dic12 = {'AIRLINE':b[0], 'DEPARTURE_DELAY':b[1]}\n",
    "    df12.loc[len(df12)] = dic12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.sample(frac=0.5, random_state=1)\n",
    "df2=df2.sample(frac=0.5, random_state=1)\n",
    "df3=df3.sample(frac=0.5, random_state=1)\n",
    "df4=df4.sample(frac=0.5, random_state=1)\n",
    "df5=df5.sample(frac=0.5, random_state=1)\n",
    "df6=df6.sample(frac=0.5, random_state=1)\n",
    "df7=df7.sample(frac=0.5, random_state=1)\n",
    "df8=df8.sample(frac=0.5, random_state=1)\n",
    "df9=df9.sample(frac=0.5, random_state=1)\n",
    "df10=df10.sample(frac=0.5, random_state=1)\n",
    "df11=df11.sample(frac=0.5, random_state=1)\n",
    "df12=df12.sample(frac=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe dimensions: (2253896, 2)\n"
     ]
    }
   ],
   "source": [
    "print('Dataframe dimensions:', dff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.sample(frac=0.2, random_state=1)\n",
    "df2=df2.sample(frac=0.2, random_state=1)\n",
    "df3=df3.sample(frac=0.2, random_state=1)\n",
    "df4=df4.sample(frac=0.2, random_state=1)\n",
    "df5=df5.sample(frac=0.2, random_state=1)\n",
    "df6=df6.sample(frac=0.2, random_state=1)\n",
    "df7=df7.sample(frac=0.2, random_state=1)\n",
    "df8=df8.sample(frac=0.2, random_state=1)\n",
    "df9=df9.sample(frac=0.2, random_state=1)\n",
    "df10=df10.sample(frac=0.2, random_state=1)\n",
    "df11=df11.sample(frac=0.2, random_state=1)\n",
    "df12=df12.sample(frac=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe dimensions: (450778, 2)\n"
     ]
    }
   ],
   "source": [
    "dff1 = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12])\n",
    "print('Dataframe dimensions:', dff1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe dimensions: (135234, 2)\n"
     ]
    }
   ],
   "source": [
    "df1=df1.sample(frac=0.3, random_state=1)\n",
    "df2=df2.sample(frac=0.3, random_state=1)\n",
    "df3=df3.sample(frac=0.3, random_state=1)\n",
    "df4=df4.sample(frac=0.3, random_state=1)\n",
    "df5=df5.sample(frac=0.3, random_state=1)\n",
    "df6=df6.sample(frac=0.3, random_state=1)\n",
    "df7=df7.sample(frac=0.3, random_state=1)\n",
    "df8=df8.sample(frac=0.3, random_state=1)\n",
    "df9=df9.sample(frac=0.3, random_state=1)\n",
    "df10=df10.sample(frac=0.3, random_state=1)\n",
    "df11=df11.sample(frac=0.3, random_state=1)\n",
    "df12=df12.sample(frac=0.3, random_state=1)\n",
    "dff2 = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12])\n",
    "print('Dataframe dimensions:', dff2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEPARTURE_DELAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190771</th>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98285</th>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194103</th>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21993</th>\n",
       "      <td>-11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131701</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130151</th>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138606</th>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16988</th>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87190</th>\n",
       "      <td>-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19605</th>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89522</th>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109741</th>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121508</th>\n",
       "      <td>-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125206</th>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66385</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53514</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106079</th>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29940</th>\n",
       "      <td>-8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32123</th>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54086</th>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13647</th>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17994</th>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41046</th>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74510</th>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153276</th>\n",
       "      <td>-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148198</th>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156268</th>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68904</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159102</th>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29696</th>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30962</th>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14246</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29129</th>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48367</th>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20179</th>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26495</th>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44020</th>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19493</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7017</th>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28898</th>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32256</th>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15461</th>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56552</th>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3785</th>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20571</th>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30533</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24891</th>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38287</th>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52526</th>\n",
       "      <td>-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10020</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20261</th>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55781</th>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24326</th>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47701</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55990</th>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41613</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25371</th>\n",
       "      <td>-10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450778 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DEPARTURE_DELAY\n",
       "190771             55.0\n",
       "98285              48.0\n",
       "194103             -3.0\n",
       "21993             -11.0\n",
       "131701              3.0\n",
       "130151             -2.0\n",
       "138606             -3.0\n",
       "16988              -6.0\n",
       "87190              -9.0\n",
       "19605              13.0\n",
       "89522             160.0\n",
       "109741             -7.0\n",
       "121508             -9.0\n",
       "125206             -3.0\n",
       "1339               -9.0\n",
       "66385               3.0\n",
       "53514               0.0\n",
       "106079             -6.0\n",
       "29940              -8.0\n",
       "32123              52.0\n",
       "54086              -1.0\n",
       "13647              15.0\n",
       "17994              -1.0\n",
       "41046              -6.0\n",
       "74510              -5.0\n",
       "153276             -9.0\n",
       "148198             -4.0\n",
       "156268             -2.0\n",
       "68904               2.0\n",
       "159102             90.0\n",
       "...                 ...\n",
       "324                 0.0\n",
       "29696              -7.0\n",
       "30962              19.0\n",
       "14246               0.0\n",
       "29129              -3.0\n",
       "48367              -2.0\n",
       "20179               7.0\n",
       "26495              15.0\n",
       "44020              -3.0\n",
       "19493               0.0\n",
       "7017               -1.0\n",
       "220                11.0\n",
       "28898              -7.0\n",
       "32256              -2.0\n",
       "15461               7.0\n",
       "56552               7.0\n",
       "3785               20.0\n",
       "20571             233.0\n",
       "30533              94.0\n",
       "24891              -2.0\n",
       "38287              -7.0\n",
       "52526              -9.0\n",
       "10020               4.0\n",
       "20261              61.0\n",
       "55781              11.0\n",
       "24326              10.0\n",
       "47701               0.0\n",
       "55990              22.0\n",
       "41613               0.0\n",
       "25371             -10.0\n",
       "\n",
       "[450778 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff1.drop(['AIRLINE'], axis = 1, inplace = True)\n",
    "dff1[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amulya\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff1=df.sample(frac=0.08, random_state=1)\n",
    "dff1.drop(['AIRLINE'], axis = 1, inplace = True)\n",
    "data_raw = dff1.values.astype(\"float32\")\n",
    "dataset=data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries (training set, test set): (366907, 91727)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SIZE = 0.80\n",
    "#dataset=dff1\n",
    "train_size = int(len(dataset) * TRAIN_SIZE)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]\n",
    "print(\"Number of entries (training set, test set): \" + str((len(train), len(test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_window(data, window_size = 1):    \n",
    "    data_s = data.copy()\n",
    "    for i in range(window_size):\n",
    "        data = pd.concat([data, data_s.shift(-(i + 1))], \n",
    "                            axis = 1)\n",
    "        \n",
    "    data.dropna(axis=0, inplace=True)\n",
    "    return(data)\n",
    "def create_dataset(dataset, window_size = 1):\n",
    "    data_X, data_Y = [], []\n",
    "    for i in range(len(dataset) - window_size - 1):\n",
    "        a = dataset[i:(i + window_size), 0]\n",
    "        data_X.append(a)\n",
    "        data_Y.append(dataset[i + window_size, 0])\n",
    "    return(np.array(data_X), np.array(data_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training data shape:\n",
      "(366905, 1)\n",
      "New training data shape:\n",
      "(366905, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "window_size = 1\n",
    "train_X, train_Y = create_dataset(train, window_size)\n",
    "test_X, test_Y = create_dataset(test, window_size)\n",
    "print(\"Original training data shape:\")\n",
    "print(train_X.shape)\n",
    "\n",
    "# Reshape the input data into appropriate form for Keras.\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(\"New training data shape:\")\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Amulya\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Amulya\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2\n",
      " - 412s - loss: 1346.7411 - accuracy: 0.0106\n",
      "Epoch 2/2\n",
      " - 398s - loss: 1346.6086 - accuracy: 0.0109\n"
     ]
    }
   ],
   "source": [
    "def fit_model(train_X, train_Y, window_size = 1):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(4, \n",
    "                   input_shape = (1, window_size)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"sgd\",\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(train_X, \n",
    "              train_Y, \n",
    "              epochs =2 , \n",
    "              batch_size = 1, \n",
    "              verbose = 2)\n",
    "    \n",
    "    return(model)\n",
    "\n",
    "# Fit the first model.\n",
    "model1 = fit_model(train_X, train_Y, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data score: 36.53 RMSE\n",
      "Test data score: 37.71 RMSE\n"
     ]
    }
   ],
   "source": [
    "def predict_and_score(model, X, Y):\n",
    "    # Make predictions on the original scale of the data.\n",
    "    w=model.predict(X)\n",
    "    #scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "    #np.reshape(w, (22696, 1))\n",
    "    #pred = scaler.inverse_transform(w)\n",
    "    pred=w\n",
    "    # Prepare Y data to also be on the original scale for interpretability.\n",
    "    orig_data = [Y]\n",
    "    # Calculate RMSE.\n",
    "    score = math.sqrt(mean_squared_error(orig_data[0], pred[:, 0]))\n",
    "    return(score, pred)\n",
    "\n",
    "rmse_train, train_predict = predict_and_score(model1, train_X, train_Y)\n",
    "rmse_test, test_predict = predict_and_score(model1, test_X, test_Y)\n",
    "\n",
    "print(\"Training data score: %.2f RMSE\" % rmse_train)\n",
    "print(\"Test data score: %.2f RMSE\" % rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 406s - loss: 1346.7576 - accuracy: 0.0105\n",
      "Epoch 2/5\n",
      " - 410s - loss: 1346.8130 - accuracy: 0.0104\n",
      "Epoch 3/5\n",
      " - 401s - loss: 1346.8009 - accuracy: 0.0107\n",
      "Epoch 4/5\n",
      " - 396s - loss: 1346.9967 - accuracy: 0.0106\n",
      "Epoch 5/5\n",
      " - 404s - loss: 1346.4319 - accuracy: 0.0109\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional\n",
    "def fit_model(train_X, train_Y, window_size = 1):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(4), input_shape=(1, window_size)))\n",
    "    #model.add(LSTM(64, input_shape =(1, window_size) ))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"sgd\",\n",
    "                   metrics=['accuracy'])\n",
    "    model.fit(train_X, \n",
    "              train_Y, \n",
    "              epochs =5 , \n",
    "              batch_size = 1, \n",
    "              verbose = 2)\n",
    "    \n",
    "    return(model)\n",
    "\n",
    "# Fit the first model.\n",
    "model1 = fit_model(train_X, train_Y, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data score: 36.77 RMSE\n",
      "Test data score: 37.34 RMSE\n"
     ]
    }
   ],
   "source": [
    "def predict_and_score(model, X, Y):\n",
    "    # Make predictions on the original scale of the data.\n",
    "    w=model.predict(X)\n",
    "    #scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "    #np.reshape(w, (22696, 1))\n",
    "    #pred = scaler.inverse_transform(w)\n",
    "    pred=w\n",
    "    # Prepare Y data to also be on the original scale for interpretability.\n",
    "    orig_data = [Y]\n",
    "    # Calculate RMSE.++++++++++++++++++++++++++++++++++++++++++++\n",
    "    score = math.sqrt(mean_squared_error(orig_data[0], pred[:, 0]))\n",
    "    return(score, pred)\n",
    "\n",
    "rmse_train, train_predict = predict_and_score(model1, train_X, train_Y)\n",
    "rmse_test, test_predict = predict_and_score(model1, test_X, test_Y)\n",
    "\n",
    "print(\"Training data score: %.2f RMSE\" % rmse_train)\n",
    "print(\"Test data score: %.2f RMSE\" % rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
